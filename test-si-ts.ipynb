{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a81cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sinhala Input: ඔබට කොහොමද?\n",
      "Tamil Translation: உங்களுக்கு எப்படி ?\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "# Path to your saved epoch 1 model\n",
    "model_dir = \"outputs_si_ta/epoch_4_model\"\n",
    "\n",
    "try:\n",
    "    # Load model and tokenizer\n",
    "    tokenizer = MBart50TokenizerFast.from_pretrained(model_dir)\n",
    "    model = MBartForConditionalGeneration.from_pretrained(model_dir)\n",
    "    model.eval()\n",
    "    \n",
    "    # Set language codes\n",
    "    tokenizer.src_lang = \"si_LK\"\n",
    "    tokenizer.tgt_lang = \"ta_IN\"\n",
    "    \n",
    "    # Example Sinhala sentence\n",
    "    sinhala_sentence = \"ඔබට කොහොමද?\"  # \"How are you?\"\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(sinhala_sentence, return_tensors=\"pt\", max_length=128, truncation=True)\n",
    "    \n",
    "    # Generate translation\n",
    "    with torch.no_grad():\n",
    "        generated_tokens = model.generate(\n",
    "            **inputs, \n",
    "            forced_bos_token_id=tokenizer.lang_code_to_id[\"ta_IN\"],\n",
    "            max_length=128,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        translation = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "    \n",
    "    print(\"Sinhala Input:\", sinhala_sentence)\n",
    "    print(\"Tamil Translation:\", translation)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Model directory '{model_dir}' not found. Available directories:\")\n",
    "    import os\n",
    "    if os.path.exists(\"outputs_si_ta\"):\n",
    "        print(os.listdir(\"outputs_si_ta\"))\n",
    "    else:\n",
    "        print(\"outputs_si_ta directory doesn't exist\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Trying to load from final model instead...\")\n",
    "    \n",
    "    # Alternative: try loading from final model\n",
    "    try:\n",
    "        model_dir = \"./final_model_si_ts-test\"  # or \"./final_model_si_ta-test\"\n",
    "        tokenizer = MBart50TokenizerFast.from_pretrained(model_dir)\n",
    "        model = MBartForConditionalGeneration.from_pretrained(model_dir)\n",
    "        print(\"Successfully loaded final model\")\n",
    "    except:\n",
    "        print(\"Final model also not found. Please check your model paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd2a39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbart50-env-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
